{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ../src/notebook_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/jcejudo/rd-img-classification-pilot/src')\n",
    "from torch_utils import *\n",
    "from ds_utils import *\n",
    "from gradcam import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_results_path = '/home/jcejudo/rd-img-classification-pilot/results'\n",
    "\n",
    "experiment_name = 'new_implementation'\n",
    "\n",
    "check_path(root_results_path)\n",
    "results_path = os.path.join(root_results_path,experiment_name)\n",
    "check_path(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "data_path = '/home/jcejudo/rd-img-classification-pilot/training_data/ec'\n",
    "ec_df = path2DataFrame(data_path)\n",
    "\n",
    "data_path = '/home/jcejudo/rd-img-classification-pilot/training_data/getty'\n",
    "getty_df = path2DataFrame(data_path)\n",
    "\n",
    "df = pd.concat((ec_df,getty_df))\n",
    "\n",
    "X = df['file_path'].values\n",
    "y = df['category'].values\n",
    "\n",
    "y_encoded, encoding_dict = label_encoding(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch training dataset class\n",
    "    X: Numpy array containing the paths to the images\n",
    "    y: Numpy array with the encoded labels\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.transform = transform\n",
    "        self.X = X\n",
    "        self.y = y        \n",
    "        self.N = y.shape[0]   \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.X[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.y[idx]\n",
    "                \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img,label\n",
    "    \n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # this normalization is required https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.33)\n",
    "\n",
    "traindata = TrainingDataset(X_train,y_train,transform=base_transform)\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=32,shuffle=True, num_workers=2)\n",
    "\n",
    "testdata = TrainingDataset(X_test,y_test,transform=base_transform)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=32,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a single device \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device, _ = check_cuda()\n",
    "#model_path = '/home/jcejudo/rd-img-classification-pilot/results/XAI/split_0/checkpoint.pth'\n",
    "net = ResNet(34,20)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader,confusion_matrix = False):\n",
    "  #accuracy\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  #confusion matrix\n",
    "  cm = None\n",
    "\n",
    "  i = 0\n",
    "\n",
    "  if confusion_matrix:\n",
    "    ground_truth_list = []\n",
    "    predictions_list = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data in dataloader:\n",
    "          #print(i)\n",
    "          images, labels = data\n",
    "        \n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "        \n",
    "          outputs = net(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "        \n",
    "          i += 1\n",
    "\n",
    "          if confusion_matrix:\n",
    "            ground_truth_list += deepcopy(labels)\n",
    "            predictions_list += list(predicted.cpu())\n",
    "\n",
    "  if confusion_matrix:\n",
    "    cm = sklearn.metrics.confusion_matrix(ground_truth_list,predictions_list,labels=np.arange(20))\n",
    "\n",
    "  return correct/total, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcejudo/.local/lib/python3.8/site-packages/PIL/Image.py:2847: DecompressionBombWarning: Image size (149839008 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#net = ConvNet(3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #print(i)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        loss = criterion(net(inputs), labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    running_loss /= i\n",
    "        \n",
    "    \n",
    "        #running_loss = 0.0\n",
    "        #if i % 100 == 99: \n",
    "    print('evaluating...')\n",
    "    acc,_ = evaluate(testloader)\n",
    "    print('[%d, %5d] loss: %.3f   test acc: %.3f' %\n",
    "          (epoch + 1, i + 1, running_loss ,acc))\n",
    "            \n",
    "            \n",
    "torch.save(net.state_dict(),os.path.join(results_path,'checkpoint.pth'))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,confusion_matrix = evaluate(testloader,confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'accuracy on test data: {acc}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
